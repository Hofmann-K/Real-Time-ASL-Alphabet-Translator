# Real-Time-ASL-Alphabet-Translator

## Introduction
The use of sign language as a mode of communication is vital for millions of people worldwide who are deaf or hard of hearing. American Sign Language (ASL) is one of the most widely used types of sign language in the United States. One of the core challenges in bridging the communication gap between the deaf community and non-signers is the lack of real-time translation tools as sign language is not taught in elementary schools and high schools alike making it very difficult for singers to be able to universally communicate with everyone.

This project aims to develop a real-time ASL alphabet translator using computer vision and machine learning techniques. The system will recognize static hand signs from the ASL alphabet (A-Z) and translate them into corresponding English letters in real time on the screen of the device running the application. This project will serve as a stepping stone towards building a more advanced system capable of recognizing words and phrases, and possibly dynamic hand movements involved in more complex signs.

## Objectives
The goal of this project is to build a system that can:
  - Detect and recognize static hand gestures from the ASL alphabet in real time.
  - Translate the recognized hand gestures into corresponding English letters.
  - Achieve high accuracy and low latency.
  - If time permits, extend the system to recognize static word signs and phrases from ASL.
  - Further expansion could include dynamic hand movements required for certain signs.

## Current State of the Project
Currently in the pre-planning and data collection phase

## Future Work
If the ASL alphabet translator is successfully completed within the project timeline, the following features will be considered as potential extensions:
  - ASL Words and Phrases: Expanding the system to recognize common static ASL words (e.g., "yes", "no", "thank you").
  - Dynamic Hand Movement Recognition: Expanding the system to recognize more complex dynamic signs that require motion to analyze, such as "please", "sorry", or "hello". This will involve having to add tracing to analyze       hand movement
